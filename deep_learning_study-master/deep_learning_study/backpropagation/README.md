# 오차역전파

가중치 매개변수의 기울기는 수치 미분을 사용했는데, 수치미분은 시간이 오래 걸린다. 오차 역전파는 이를 보완해준다.

### 그래프를 이용한 계산 

O는 100원, ㅁ는 150원, 소비서 10%
 100 2 200  650  1.1  715
    O--> * --> + --> *    -->
      150 3 450 
    ㅁ--> * -->

-->방향으로 계산하는 것이 순방향이다.

계산 그래프의 특징은 '국소적 계산' 이다.
=> 자신과 관계된 정보만으로 다음 결과 출력 가능. 각 노드는 자신과 관련한 계산만 신경쓰면 됨. 이런 계산이 모이면 복잡한 계산이 됨.

### 연쇄법칙

    <-----  f  <----- 
    E(σy/σx)    E

E 에 국소적 미분을 곱하고, 다음 노드로 전달.

합성 함수의 미분에 대한 성질
합성 함수의 미분은 합성함수를 구성 하는 각 함수의 곱으로 나타낼 수 있다.

    z = t^2, t = x+y

    σz/σx = (σz/σt)(σt/σx)

    σz/σt = 2t  , σt/σx = 1
    2t*1 = 2(x+y)    
      x         t          z
    ----->  +  ----->  ^2 ----->
    <-----     <-----     <-----
    (σt/σx) (σz/σt)(σz/σz)     σz/σz
    (σz/σz)
    (σz/σt)


역전파가 하는 일은 연쇄법칙과 같음.

### 덧셈노드
z = x+ y
σz/σx= 1, σz/σy 1

    x <-----
      1*σL/σz  +  <------
    y <-----       σL/σz
      1*σL/σz
      
 ### 곱셈노드
 
 z = xy
 σz/σx = y, σz/σy = x
 
     x <-----      
        y*σL/σz  * <-------   
     y <-----         σL/σz
        x*σL/σz
        
## 활성화 함수 계층

### sigmoid 계층

    y = 1 / (1+exp(-x))
    

     x       -x     exp(-x)  1+exp(x)   1/(1+exp(-x))
    ----> * ----> exp ----> + ---->    / ----->
          -1                1
          
y = 1/x, σy/σx = - 1/x^2
y = exp(x), σy/σx = exp(x)

           -1                      1
     <----  *  <----  exp   <----  +  <----    / <-----
     (σL/σy)   -(σL/σy)      -(σL/σy)  (σL/σy)    (σL/σy)
     y^2        y^2          y^2       y^2
     *exp(-x)   *exp(-x)
     
     
    <-------- sigmoid  <--------
    (σL/σy)             (σL/σy)
    y^2
    exp(-x)
    
    식을 정리하면,
    (σL/σy) = (σL/σy)*y*(1-y)
    
    출력 y만으로 역전파계산 가능.
    
### ReLU계층

    y = x (x>0)
        0 (x<=0)
    
    (σy/σx) = 1 (x>0)
              0 (x<=0)
             x>0                           x<=0 
    <------ ReLU <------           <------ ReLU <-----
     (σL/σy)       (σL/σy)           0           (σL/σy)
  
  
### Affine 계층

신경망의 순전파에서는 행렬의 내적이 사용됬다. 행렬의 내적을 기하학에서는 affine 변환이라고 한다.
     
    X(2,)
    ----->      X'W(3,)      Y(3,)
             dot -----> + ------>
    ----->             B(3,)
    W(2,3)

   σL/σx =(σL/σy)W.T,  σL/σw = X.T(σL/σy)
   .T는 전치행렬. w(i,j) 의 전치행렬은 w(j,i)
      
      1
   <-----
          dot ------ + <------
   <-----     σL/σy(3,) σL/σy(3,)
      2
     
   1: σL/σx =(σL/σy)W.T,  2: σL/σw = X.T(σL/σy)
   
배치의 경우에는 x의 형상이 (N,2)로 됨.
