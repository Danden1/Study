# 합성곱 신경망(CNN)

## 전체구조

합성곱 계층과 풀링계층이 새롭게 등장.

Conv -> ReLu -> Pooling -> Conv ->ReLU -> Affine -> ReLU -> Affine -> Softmax ->

Pooling 계층은 생략하기도 한다.
출력층에서 가까운 층은 Affine -> ReLU 구성 사용 가능
마지막 출력층에서는 Affine->softmax사용.

## 합성곱계층

완전 연결 : 인접하는 계층의 모든 뉴런과 결합되있음.

### 완전연결 계층의 문제점

'데이터의 형상이 무시됨'

이미지는 보통 세로,가로, 채널(색상)으로 구성된 3차원 데이터.
그러나 완전 연결 계층에 입력활 때는 3차원을 1차원 데이터로 바꿔야 됨.

CNN에서 합성곱 계층의 입출력 데이터를 특징 맵(feature map)이라고 함.

### 합성곱 연산

    1 | 2 | 0
    3 | 1 | 2  *      2 | 1   -->   |
    0 | 1 | 2         3 | 1         |
    
    입력데이터          필터(커널)    출력
    (3,3)              (2,2)       (2,2)

필터의 윈도우를 일정 간격으로 이동해 가며 입력데이터에 적용. 
입력과 필터에서 대응하는 원소끼리 곱한후 그 총합을 구함.(단일 곱셈-누산)

    1 || 2 | 0
    3 || 1 | 2 * 2|1    --> 14|
    0 |  1 | 2   3|1          |
    
    || : window
    
    1*2 + 2*1 + 3*3 + 1*1 = 14


필터의 매개변수가 가중치

편향은,

    14|9 + 1 -> 15|10
    8 |9         9|10
           b
    편향은 항상 (1,1)
    
### 패딩(padding)

패딩 : 합성곱 연산 전에 데이터 주변을 특정 값(0)으로 채우는 것.

폭이 1인 패딩

0  0   0   0  0
0  1 | 2 | 0  0 
0  3 | 1 | 2  0 
0  2 | 1 | 2  0
0  0   0   0  0

패딩은 주로 출력 크기 조정 하는 데 사용

### 스트라이드 (stride)

스트라이드 : 필터를 적용하는 위치의 간격.

앞에 예제는 스트라이드가 1이 여서, 필터를 적용한 윈도우가 1칸 씩 움직였음.

스트라이드를 키우면 출력이 작아짐. 패딩은 크게 하면 출력은 커짐.
수식화 하면,

    OH= (H + 2P - FH)/S + 1
    OW = (W+2P-FW)/S +1
    
    입력의 크기 : (H,W), 필터 크기 : (FH, FW) 출력 크기 : (OH, OW)
    패딩 : P 스트라이드 : S
    
    단, 정수로 나눠 떨어지는 값이어야됨.
    
### 3차원 데이터 합성곱

(채널, 높이, 너비): (C, H, W)

(H,W)모양의 입력데이터가 C개
(H,W)모양의 필터도 C개
단 출력은 1개

    ex)                                           (6+12)
    1 | 2 | 0   1 | 3 | 1       1 | 0    3 | 2  -> 18|
    1 | 3 | 1   2 | 1 | 2    *  2 | 1  , 1 | 1       |
    1 | 1 | 1 , 1 | 1 | 3
 
 
출력을 여러개 하고 싶으면
(C, FH, FW)같은 필터를 FN개 적용하면, 출력도 FN개 생김.
출력은 (FN, OH,OW)인 블록 모양이 됨.
이 블록을 다음 계층으로 넘기는 것이 CNN의 흐름
편향을 쓸려면 (FN,1,1,)모양으로 하면 됨.

### 배치

N 개의 데이터
(N,C,H,W) * (FN,C,FH,FW) - > (N, FN, OH, OW)
4차원 데이터가 흐른다.
4차원 데이터가 하나 흐를 때마다
데이터 N개에 대한 합성곱 연산이 이루어짐.
즉, N차원의 처리를 한 번에 함.

## 풀링 계층

풀링 : 가로, 세로 방향의 공간을 줄이는 연산
    ex) 2*2, 최대 풀링은 스트라이드 2로 처리
    1 || 2 | 1 | 0
    0 || 1 | 2 | 3
    3 | 0 | 1 | 2   ->  2 |
    2 | 4 | 0 | 1         |
    
    가장 큰 원소 하나를 꺼냄.
    
 

### 특징

학습해야 할 매개변수가 없음.
채널 수가 변하지 않음(입력채널 = 출력 채널).
입력의 변화에 영향을 적게 받음.


## 구현

### 4차원 배열

    x = np.random.rand(10,1,28,28) # (개수, 채널, 높이, 너비)
    x.shape # (10,1,28,28(
    
    10개 중 1번재 데이터에 접근
    x[0].shape #(1,28,28)
    
    첫번째 데이터, 첫 채널의 공간 데이터에 접근
    x[0][0]
    
### im2col로 데이터 전개

im2col은 입력 데이터를 필터링 하기 좋게 전개하는 함수.
            
          _   _
        /      /   im2col
        |     | |  ------>  행렬 
        |     | /
                                                      reshape
            입력             *(내적)   -->  2차원 출력 ---->     원래 모양으로
            
         (1,1) *n    ----->  행렬
     
        필터
        
